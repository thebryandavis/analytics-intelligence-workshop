{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# Notebook 3: Anomaly Detection & Alerts\n",
    "\n",
    "## Making It Automatic ü§ñ\n",
    "\n",
    "**üëã Recap:** In Notebooks 1 & 2, you:\n",
    "- Explored data manually\n",
    "- Used AI to generate SQL\n",
    "- Found all 6 planted issues\n",
    "\n",
    "**But...** you ran everything manually. That doesn't scale.\n",
    "\n",
    "---\n",
    "\n",
    "## What We're Building\n",
    "\n",
    "A **fully automated system** that:\n",
    "1. ü§ñ **Classifies** findings (critical problem? opportunity? minor issue?)\n",
    "2. üì® **Sends Slack alerts** with smart recommendations\n",
    "3. ‚öôÔ∏è **Runs from YAML config** (add checks without coding)\n",
    "4. üöÄ **Deploys to production** (GitHub Actions, Cloud Functions, etc.)\n",
    "\n",
    "**By the end:** You'll see alerts arrive in Slack in real-time!\n",
    "\n",
    "Let's finish strong! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Setup\n",
    "\n",
    "**What this does:** Installs everything + imports libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q openai google-cloud-bigquery pandas requests\n",
    "\n",
    "print(\"‚úì Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from google.cloud import bigquery\n",
    "from google.colab import auth\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"‚úì Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auth"
   },
   "source": "---\n\n## Step 2: Authenticate & Configure\n\n**üìù Update these values:**\n- `OPENAI_API_KEY`: From platform.openai.com\n- `SLACK_WEBHOOK`: From api.slack.com (optional - or just watch!)\n- BigQuery project already configured"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth_code"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Cloud\n",
    "auth.authenticate_user()\n",
    "print(\"‚úì Google Cloud authenticated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": "# Configuration\nPROJECT_ID = \"npa-workshop-2025\"  # ‚¨ÖÔ∏è Workshop project ID\nDATASET_ID = \"npa_workshop\"\nTABLE_ID = \"news_events\"\nTABLE_REF = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n\n# OpenAI (for classification)\nOPENAI_API_KEY = \"sk-your-key-here\"  # ‚¨ÖÔ∏è UPDATE THIS\n\n# Initialize OpenAI client (new API v1.0+)\nfrom openai import OpenAI\nclient_openai = OpenAI(api_key=OPENAI_API_KEY)\n\n# Slack (optional - can skip if just watching)\nSLACK_WEBHOOK = \"https://hooks.slack.com/services/YOUR/WEBHOOK/URL\"  # ‚¨ÖÔ∏è UPDATE THIS (optional)\n\n# BigQuery client\nclient = bigquery.Client(project=PROJECT_ID)\n\nprint(\"‚úì Configuration complete!\")\nprint(f\"  BigQuery: {TABLE_REF}\")\nprint(f\"  OpenAI: {OPENAI_API_KEY[:10]}...\" if OPENAI_API_KEY.startswith('sk-') else \"  ‚ö†Ô∏è No OpenAI key\")\nprint(f\"  Slack: {SLACK_WEBHOOK[:40]}...\" if SLACK_WEBHOOK.startswith('https://hooks') else \"  ‚ö†Ô∏è No Slack webhook (optional)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "classifier_intro"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 1: AI Classification üß†\n",
    "\n",
    "**The problem:** We found issues, but how do we know if they're critical?\n",
    "\n",
    "**The solution:** Use OpenAI **function calling** to classify findings.\n",
    "\n",
    "**How it works:**\n",
    "1. Give AI the finding (\"iOS tracking stopped\")\n",
    "2. Ask it to classify using a structured format\n",
    "3. Get back JSON: category, severity, title, message, recommendation, emoji\n",
    "\n",
    "**This is like giving the AI a form to fill out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classifier_func"
   },
   "outputs": [],
   "source": "def classify_finding(finding_description, model=\"gpt-4\"):\n    \"\"\"\n    Use OpenAI function calling to classify an analytics finding.\n    \n    Returns structured JSON with category, severity, title, message, etc.\n    \"\"\"\n    tools = [{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"classify_analytics_finding\",\n            \"description\": \"Classify an analytics finding as problem or opportunity\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"category\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"problem_critical\", \"problem_minor\", \"opportunity\", \"informational\"],\n                        \"description\": \"Type of finding\"\n                    },\n                    \"severity\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"high\", \"medium\", \"low\"],\n                        \"description\": \"How urgent is this?\"\n                    },\n                    \"title\": {\n                        \"type\": \"string\",\n                        \"description\": \"Short, clear title (< 50 chars)\"\n                    },\n                    \"message\": {\n                        \"type\": \"string\",\n                        \"description\": \"Detailed explanation of what was found\"\n                    },\n                    \"recommendation\": {\n                        \"type\": \"string\",\n                        \"description\": \"Specific next steps to take\"\n                    },\n                    \"emoji\": {\n                        \"type\": \"string\",\n                        \"description\": \"Single emoji representing severity/category\"\n                    }\n                },\n                \"required\": [\"category\", \"severity\", \"title\", \"message\", \"recommendation\", \"emoji\"]\n            }\n        }\n    }]\n    \n    response = client_openai.chat.completions.create(\n        model=model,\n        messages=[{\n            \"role\": \"user\",\n            \"content\": f\"Classify this analytics finding:\\n\\n{finding_description}\"\n        }],\n        tools=tools,\n        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"classify_analytics_finding\"}}\n    )\n    \n    result = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n    return result\n\nprint(\"‚úì Classification function defined!\")\nprint(\"\\nReady to classify findings with AI! ü§ñ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_classify"
   },
   "source": [
    "---\n",
    "\n",
    "## Test: Classify iOS Tracking Break\n",
    "\n",
    "**Let's classify the iOS issue we found in Notebook 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classify_ios"
   },
   "outputs": [],
   "source": [
    "# The finding from Notebook 2\n",
    "finding = \"\"\"\n",
    "iOS scroll_depth events dropped to zero after 2pm on October 3rd, 2025.\n",
    "Expected approximately 2,100 events per hour based on historical average.\n",
    "Found 842 events at 2pm, then 0 events for all subsequent hours.\n",
    "This affects all iOS users and completely blocks engagement metrics.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Finding: iOS scroll_depth tracking stopped\\n\")\n",
    "print(\"ü§ñ Classifying with OpenAI function calling...\\n\")\n",
    "\n",
    "classification = classify_finding(finding)\n",
    "\n",
    "print(\"üìä Classification Result:\")\n",
    "print(\"=\" * 70)\n",
    "print(json.dumps(classification, indent=2))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n‚ú® Perfect! AI classified this as:\")\n",
    "print(f\"   Category: {classification['category']}\")\n",
    "print(f\"   Severity: {classification['severity']}\")\n",
    "print(f\"   Emoji: {classification['emoji']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "classify_opportunity"
   },
   "source": [
    "---\n",
    "\n",
    "## Test: Classify Newsletter Spike\n",
    "\n",
    "**Now let's classify good news - the newsletter spike!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classify_newsletter"
   },
   "outputs": [],
   "source": [
    "finding = \"\"\"\n",
    "Newsletter signup events increased 45% on October 4th, 2025.\n",
    "Previous day had 17,500 signups.\n",
    "October 4th had 25,375 signups.\n",
    "This is significantly above the weekly baseline and represents positive momentum.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Finding: Newsletter signups spiked\\n\")\n",
    "print(\"ü§ñ Classifying...\\n\")\n",
    "\n",
    "classification = classify_finding(finding)\n",
    "\n",
    "print(\"üìä Classification Result:\")\n",
    "print(\"=\" * 70)\n",
    "print(json.dumps(classification, indent=2))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n‚ú® Notice the difference!\")\n",
    "print(f\"   Category: {classification['category']} (not a problem!)\")\n",
    "print(f\"   Emoji: {classification['emoji']} (celebration!)\")\n",
    "print(f\"\\n   Same system, different tone. The AI understands context! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slack_intro"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 2: Slack Alerts üì®\n",
    "\n",
    "**Now let's send these classifications to Slack!**\n",
    "\n",
    "**How it works:**\n",
    "1. Take the classification JSON\n",
    "2. Format it into a nice Slack message\n",
    "3. Color-code by severity (red = critical, green = opportunity)\n",
    "4. Send via webhook\n",
    "\n",
    "**‚ö†Ô∏è Note:** You need a Slack webhook URL. If you don't have one, that's okay - you'll see the formatted message here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slack_func"
   },
   "outputs": [],
   "source": [
    "def send_slack_alert(classification, webhook_url=None):\n",
    "    \"\"\"\n",
    "    Send classification to Slack as a formatted alert.\n",
    "    \"\"\"\n",
    "    # Color mapping\n",
    "    colors = {\n",
    "        \"problem_critical\": \"danger\",    # Red\n",
    "        \"problem_minor\": \"warning\",      # Yellow\n",
    "        \"opportunity\": \"good\",           # Green\n",
    "        \"informational\": \"#439FE0\"       # Blue\n",
    "    }\n",
    "    \n",
    "    color = colors.get(classification['category'], \"#439FE0\")\n",
    "    \n",
    "    # Build Slack message\n",
    "    payload = {\n",
    "        \"attachments\": [{\n",
    "            \"color\": color,\n",
    "            \"title\": f\"{classification['emoji']} {classification['title']}\",\n",
    "            \"text\": classification['message'],\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"title\": \"Category\",\n",
    "                    \"value\": classification['category'].replace('_', ' ').title(),\n",
    "                    \"short\": True\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Severity\",\n",
    "                    \"value\": classification['severity'].upper(),\n",
    "                    \"short\": True\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Recommendation\",\n",
    "                    \"value\": classification['recommendation'],\n",
    "                    \"short\": False\n",
    "                }\n",
    "            ],\n",
    "            \"footer\": \"Analytics Intelligence\",\n",
    "            \"footer_icon\": \"https://platform.slack-edge.com/img/default_application_icon.png\",\n",
    "            \"ts\": int(datetime.now().timestamp())\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    # Print formatted message\n",
    "    print(\"\\nüì® Slack Alert Preview:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{classification['emoji']} {classification['title']}\")\n",
    "    print(f\"\\nCategory: {classification['category']} | Severity: {classification['severity'].upper()}\")\n",
    "    print(f\"\\n{classification['message']}\")\n",
    "    print(f\"\\nRecommendation: {classification['recommendation']}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Send to Slack if webhook provided\n",
    "    if webhook_url and webhook_url.startswith('https://hooks.slack.com'):\n",
    "        try:\n",
    "            response = requests.post(webhook_url, json=payload)\n",
    "            if response.status_code == 200:\n",
    "                print(\"\\n‚úì Alert sent to Slack successfully!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è Slack webhook returned status {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Error sending to Slack: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No Slack webhook configured (that's okay - this is just a preview!)\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Slack alerter function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "send_alert"
   },
   "source": [
    "---\n",
    "\n",
    "## Send Alert: iOS Tracking Break\n",
    "\n",
    "**üéØ BIG MOMENT: Let's send the iOS alert to Slack!**\n",
    "\n",
    "*(If you don't have a webhook, you'll still see a preview)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "send_ios_alert"
   },
   "outputs": [],
   "source": [
    "# Use the iOS classification from earlier\n",
    "finding = \"\"\"\n",
    "iOS scroll_depth events dropped to zero after 2pm on October 3rd, 2025.\n",
    "Expected ~2,100 events/hour, found 842 at 2pm then 0 after.\n",
    "Affects all iOS users and blocks engagement metrics.\n",
    "\"\"\"\n",
    "\n",
    "classification = classify_finding(finding)\n",
    "\n",
    "print(\"üì§ Sending alert to Slack...\\n\")\n",
    "\n",
    "send_slack_alert(classification, SLACK_WEBHOOK)\n",
    "\n",
    "print(\"\\nüí° Check your Slack channel! (if webhook is configured)\")\n",
    "print(\"   You should see a red alert with the iOS tracking issue!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "send_opportunity"
   },
   "source": [
    "---\n",
    "\n",
    "## Send Alert: Newsletter Opportunity\n",
    "\n",
    "**Now let's send the good news!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "send_newsletter_alert"
   },
   "outputs": [],
   "source": [
    "finding = \"\"\"\n",
    "Newsletter signups increased 45% on October 4th (25,375 vs 17,500).\n",
    "Significantly above weekly baseline.\n",
    "Positive momentum worth investigating.\n",
    "\"\"\"\n",
    "\n",
    "classification = classify_finding(finding)\n",
    "\n",
    "print(\"üì§ Sending opportunity alert to Slack...\\n\")\n",
    "\n",
    "send_slack_alert(classification, SLACK_WEBHOOK)\n",
    "\n",
    "print(\"\\nüéâ This should appear in green! Same system, different tone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automation"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 3: Full Automation üöÄ\n",
    "\n",
    "**Now let's tie it all together:**\n",
    "1. Generate SQL from description\n",
    "2. Run query\n",
    "3. Classify results\n",
    "4. Send Slack alert\n",
    "\n",
    "**All in one function!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_check_func"
   },
   "outputs": [],
   "source": "def run_check(check_name, check_description, slack_webhook=None):\n    \"\"\"\n    Complete check workflow:\n    1. Generate SQL from description\n    2. Execute query\n    3. Classify results if found\n    4. Send Slack alert\n    \"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"üîç Running Check: {check_name}\")\n    print(f\"{'='*70}\")\n    \n    # Step 1: Generate SQL\n    print(\"\\n1Ô∏è‚É£ Generating SQL with GPT...\")\n    \n    # Get schema\n    table = client.get_table(TABLE_REF)\n    schema_info = \"\\n\".join([f\"- {field.name}: {field.field_type}\" for field in table.schema])\n    \n    # Generate SQL (using new API)\n    prompt = f\"\"\"Generate BigQuery SQL for: {check_description}\n    \nTable: `{TABLE_REF}`\nSchema:\n{schema_info}\n\nReturn only SQL, no explanation.\"\"\"\n    \n    response = client_openai.chat.completions.create(\n        model=\"gpt-3.5-turbo\",  # Cheaper for SQL generation\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0\n    )\n    \n    sql = response.choices[0].message.content.strip()\n    if sql.startswith('```'):\n        sql = sql.split('```')[1]\n        if sql.startswith('sql\\n'):\n            sql = sql[4:]\n    sql = sql.strip()\n    \n    print(f\"   ‚úì SQL generated ({len(sql)} chars)\")\n    \n    # Step 2: Execute\n    print(\"\\n2Ô∏è‚É£ Executing query...\")\n    try:\n        df = client.query(sql).to_dataframe()\n        print(f\"   ‚úì Query complete ({len(df)} rows)\")\n    except Exception as e:\n        print(f\"   ‚úó Query failed: {e}\")\n        return None\n    \n    # Step 3: Classify if results found\n    if len(df) > 0:\n        print(\"\\n3Ô∏è‚É£ Classifying findings...\")\n        finding_summary = f\"{check_name}: Found {len(df)} rows. Sample:\\n{df.head(3).to_string()}\"\n        classification = classify_finding(finding_summary)\n        print(f\"   ‚úì Classified as: {classification['category']} ({classification['severity']})\")\n        \n        # Step 4: Send alert\n        print(\"\\n4Ô∏è‚É£ Sending Slack alert...\")\n        send_slack_alert(classification, slack_webhook)\n        \n        return classification\n    else:\n        print(\"\\n   ‚ÑπÔ∏è No issues found - check passed!\")\n        return None\n\nprint(\"‚úì Full automation function defined!\")\nprint(\"\\nReady to run complete checks! üéâ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_all"
   },
   "source": [
    "---\n",
    "\n",
    "## Run All Checks\n",
    "\n",
    "**üéØ CLIMAX: Let's run all 6 checks and watch the alerts fly!**\n",
    "\n",
    "This will:\n",
    "- Generate SQL for each check\n",
    "- Execute queries\n",
    "- Classify findings\n",
    "- Send Slack alerts\n",
    "\n",
    "**All automatically!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_all_checks"
   },
   "outputs": [],
   "source": [
    "# Define all checks\n",
    "checks = [\n",
    "    {\n",
    "        \"name\": \"Missing Consent State\",\n",
    "        \"description\": \"Find events where consent_state is NULL. Group by date/platform, show percentage missing. Flag if >10%.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"iOS Scroll Tracking Break\",\n",
    "        \"description\": \"Find hours where iOS scroll_depth events < 1000. Show date, hour, count.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"PII in URLs\",\n",
    "        \"description\": \"Find page_location containing 'email=' or '@'. Show URL and count. Limit 10.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Duplicate Events\",\n",
    "        \"description\": \"Find duplicate user_pseudo_id + event_timestamp. Show count > 1. Limit 20.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Newsletter Signup Spike\",\n",
    "        \"description\": \"Find days where newsletter_signup count increased >30% from previous day.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"New Referrer Source\",\n",
    "        \"description\": \"Find referrers in recent days (>= 20251005) not in earlier days.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üöÄ Running all 6 checks...\")\n",
    "print(\"\\nThis will take ~60 seconds (6 SQL generations + executions)\\n\")\n",
    "\n",
    "results = []\n",
    "for i, check in enumerate(checks, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Check {i}/{len(checks)}: {check['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result = run_check(\n",
    "        check_name=check['name'],\n",
    "        check_description=check['description'],\n",
    "        slack_webhook=SLACK_WEBHOOK\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(\"‚úÖ ALL CHECKS COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nFindings: {len(results)}\")\n",
    "for r in results:\n",
    "    print(f\"  {r['emoji']} {r['title']} ({r['category']})\")\n",
    "\n",
    "if SLACK_WEBHOOK.startswith('https://hooks.slack.com'):\n",
    "    print(f\"\\nüí¨ Check your Slack channel - you should have {len(results)} alerts!\")\n",
    "else:\n",
    "    print(f\"\\nüí° Configure SLACK_WEBHOOK to see alerts in Slack!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complete"
   },
   "source": "---\n\n# üéâ Workshop Complete!\n\n## What You Built\n\nA complete **Analytics Intelligence System** that:\n\n1. ‚úÖ **Generates SQL** from plain English (no SQL expertise needed)\n2. ‚úÖ **Finds problems** (missing consent, tracking breaks, PII leaks, duplicates)\n3. ‚úÖ **Finds opportunities** (traffic spikes, new referrers)\n4. ‚úÖ **Classifies findings** with AI (critical vs minor, problem vs opportunity)\n5. ‚úÖ **Sends Slack alerts** automatically\n6. ‚úÖ **Runs on schedule** (ready for production!)\n\n---\n\n## What You Discovered\n\n**In 90 minutes, you found:**\n- 4+ problems (GDPR risk, PII leak, duplicates, data quality issues)\n- 2 opportunities (newsletter spike, new traffic source)\n\n**Without writing a single line of SQL!**\n\n---\n\n## Deployment Options\n\n**To run this in production:**\n\n### Option 1: GitHub Actions (Recommended)\n- Free for public repos\n- Runs on schedule (every 6 hours)\n- 10-minute setup\n- See workshop materials for instructions\n\n### Option 2: Google Cloud Functions\n- Native BigQuery integration\n- Serverless, auto-scaling\n- Generous free tier\n\n### Option 3: Cron Job\n- Simplest if you have a server\n- One line in crontab\n- Zero additional cost\n\n---\n\n## Cost Summary\n\n**This workshop:**\n- BigQuery: $0 (free tier)\n- OpenAI: ~$0.50 (GPT-4 + GPT-3.5-turbo)\n- Slack: $0\n- **Total: < $1**\n\n**Production (running 4x/day):**\n- BigQuery: ~$5/month\n- OpenAI (GPT-3.5-turbo): ~$3/month\n- Compute: $0 (GitHub Actions)\n- **Total: < $10/month**\n\n**ROI:** Catch one tracking break early ‚Üí save thousands in lost data\n\n---\n\n## Next Steps\n\n### Today\n1. ‚≠ê Save these notebooks\n2. üìã Review the workshop materials\n3. üìß Reach out with questions: **brdavis@ap.org**\n\n### This Week\n1. Get OpenAI API key (platform.openai.com)\n2. Load your data to BigQuery\n3. Run notebooks with your data\n4. Customize checks for your tracking plan\n\n### This Month\n1. Deploy to GitHub Actions\n2. Configure Slack alerts\n3. Add your custom checks\n4. Catch your first issue!\n5. Share your success story!\n\n---\n\n## Resources\n\n**Workshop Materials:**\n- All 3 notebooks (you have them!)\n- Additional documentation available on request\n\n**Support:**\n- Email: **brdavis@ap.org**\n- Follow-up questions welcome!\n\n---\n\n## Thank You! üôè\n\nYou just learned how to:\n- Build analytics monitoring with AI\n- Find problems before they cost thousands\n- Discover opportunities while they're happening\n- Deploy production systems for < $10/month\n\n**That's powerful!** üí™\n\n---\n\n**Presented by:**\nBryan Davis  \nDirector of Product, Data & Analytics  \nThe Associated Press  \n**brdavis@ap.org**\n\n---\n\n**Questions?** Email me: **brdavis@ap.org**\n\n**Now go build something awesome!** üöÄ"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Analytics Intelligence - Notebook 3: Anomaly Detection & Alerts",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}